# Fine-Tuning Branch

This branch is dedicated to model fine-tuning and benchmark testing. We focus on two versions of the Llama model: **Llama3.2** and **Llama3.3**. Below are the supported models and their performance metrics across different tasks.

#### Models Used

- **Llama3.2**
- **Llama3.3**

#### Benchmark Results

| Model    | Parameters | VRAM Consumption | Crypto Knowledge (10) | Trading Knowledge (10) | Multi-Step Workflow Execution (10) |
|----------|------------|-------------------|-----------------------|------------------------|-------------------------------------|
| Llama3.1 | 8B         | 19.2GB             | -                    | -                     | -                                  |
| Llama3.2 | 1B         | 2.5GB              | -                    | -                     | -                                  |
| Llama3.2 | 3B         | 6.5GB              | -                    | -                     | -                                  |
| Llama3.3 | 70B        | 128GB              | -                    | -                     | -                                  |

---
#### Quantization & Final Testing

TBD

---

## Powered By
<h1 align="center" style="height: 200px; overflow: hidden; ">
  <img src="unsloth-main/images/ollama.png" style="width: 8%;" alt="ollama" >
  <img src="unsloth-main/images/unsloth%20new%20logo.png" style="width: 20%;" alt="unsoloth" >
</h1>

